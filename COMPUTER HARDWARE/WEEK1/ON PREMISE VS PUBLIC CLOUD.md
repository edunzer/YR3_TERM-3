## ON PREMISE VS PUBLIC CLOUD

__Section 1__
  *Deliverables*
    `One of the first areas that I think of to improve the amount of sendable data to different components is the motherboard. If your board is not capable to run a certain speeds and canâ€™t handle certain amounts of data transfer, then there is a huge bottleneck in component performance. The next item would have to be the RAM. Considering that most cpu bottlenecks only happen when there is limited ram to store processes it seems to be a huge issue and could have a huge impact on performance. The next thing that I think of when it comes to latency is the simple network card. This has more to do with data transfer in an out of a machine but when it comes to sending data out of a computer network cards can halt everything and put huge amount of latency on data transfer.  `

__Section 2__
  *Deliverables*
    `I have always thought that large scale compute providers are much more efficient. Not only do most have great systems but they are stored in an efficient manner which is becoming the largest problem with huge amounts of compute power. Not only do off site compute location often have there own staff to take care of the systems and regulate them but they also enable the end user or who ever is purchasing the compute power to only worry about the service that they are receiving. With redundant cloud storage hardware failure is a lot less of a worry and instead the user can just deal with there data and use of the hardware. `
